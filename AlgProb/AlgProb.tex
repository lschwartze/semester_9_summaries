\documentclass[a4paper, 12pt]{article}

\usepackage{fullpage}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb}
\usepackage[explicit]{titlesec}
\usepackage{ulem}
\usepackage[onehalfspacing]{setspace}
\usepackage{amsthm}

\theoremstyle{plain}
\newtheorem{theorem}{Satz}[section] % reset theorem numbering for each chapter

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition} % definition numbers are dependent on theorem numbers
\theoremstyle{lemma}
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Bemerkung}

\theoremstyle{corollary}
\newtheorem{corollary}[theorem]{Korollar}

\theoremstyle{example}
\newtheorem{example}[theorem]{Beispiel}

\titleformat{\subsection}
{\small}{\thesubsection}{1em}{\uline{#1}}
\begin{document}
	\begin{titlepage} 
		\title{Algorithmen für schwierige Probleme}
		\clearpage\maketitle
		\thispagestyle{empty}
	\end{titlepage}
	\tableofcontents
	\newpage
	\section{3-SAT und Vertex Cover}
	\subsection{Vertex Cover}
	\begin{definition}
		Ein Vertex Cover für einen Graphen $G$ ist eine Teilmenge $C \subseteq V$ der Knoten, sodass $\forall e = (u,v) \in E$ gilt $u \in C$ oder $v \in C$. 
	\end{definition}
	\begin{definition}
		Für zwei Probleme $A$, $B$ schreiben wir $A \preceq B$, wenn man $A$ effizient auf $B$ transformieren kann.
	\end{definition}
	\begin{theorem}
		Der Greedy Algorithmus, der immer den Knoten höchsten Grades wählt, kann beliebig schlechte Ergebnisse liefern.
	\end{theorem}
	\begin{theorem}
		Der folgende Algorithmus liefert eine 2-Faktor-Approximation an das optimale Vertex Cover.
		\begin{enumerate}
			\item setze $C= \varnothing$
			\item WHILE $E \neq \varnothing$
			\item wähle eine Kante $(u,v)$
			\item setze $V = V\setminus \{u,v\}$, $E = {e = (w,x) \in E \; | \; w,x \notin \{u,v\}}$ und $C = C \cup \{u,v\}$.
		\end{enumerate}
	\end{theorem}
	\begin{theorem}
		Der folgenden Ansatz benutzt außerdem einen Parameter $k$ als Eingabe und entscheidet, ob es ein Vertex Cover der Größe $\leq k$ gibt.
		\begin{enumerate}
			\item FUNCTION VCover($G,C,l$)
			\item if $E = \varnothing$ return True
			\item if $l = k$ return False
			\item Wähle eine Kante $(u,v)$ in $G$
			\item if VCover($G\setminus \{u\}, C \cup \{u\}, l+1$)
			\item return True
			\item else return VCover($G\setminus \{v\}, C\cup \{v\}, l+1$)
		\end{enumerate}
	Die Laufzeit ist offensichtlich $2^k \mathcal{O}(n)$.
	\end{theorem}
	\subsection{SAT}
	Eine Formel $F$ ist in KNF gegeben, also als Konjunktion von Disjunktionen von Literalen. Eine Belegung ist eine Funktion, die jeder Variable einen Wert zuweist. Eine partielle Belegung weist nur einer Teilmenge aller Variablen Werte zu und lässt die restlichen undefiniert.
	\begin{lemma}
		Reduktion von 3-Färbbarkeit auf SAT.\\
		Für einen Graphen $G$ wollen wir eine Formel $F$ konstruieren. Zunächst definieren wir die Menge der Variablen von $F$ als \[VAR = \{x_v^1, x_v^2, x_v^3: \; v \in V\}\] für drei verschiedene Farben. In einer Lösung muss jeder Knoten eine Farbe bekommen, d.h wir brauchen die $\left|V\right|$ Klauseln \[(x_v^1 \lor x_v^2 \lor x_v^3)\] Außerdem dürfen zwei benachbarte Knoten nicht dieselbe Farbe bekommen, das heißt, es ergeben sich die $3\left|E\right|$ Klauseln \[(\lnot {x_v^1} \lor \lnot {x_w^1}) \land (\lnot {x_v^2} \lor \lnot {x_w^2}) \land (\lnot {x_v^3} \lor \lnot {x_w^3})\] 
	\end{lemma}
	\begin{theorem}
		Der folgende \underline{Backtracking} Algorithmus bietet einen guten Ansatz, um eine Formel $F$ auf Erfüllbarkeit zu überprüfen.
		\begin{enumerate}
			\item FUNCTION search($F, \alpha$ partielle Belegung)
			\item if $\alpha$ belegt alle Variablen: return $\alpha(F)$
			\item if $\alpha$ belegt eine Klausel mit 0: return False
			\item if search($F, \alpha0$) = True: return True
			\item else: return search($F,\alpha1$)
		\end{enumerate}
		Dieser Algorithmus kann sogar noch weiter verbessert werden, indem zuerst nach Klauseln mit nur einem Literal gesucht wird und dann diese belegt werden. Wenn diese nicht existieren, wird nach Klauseln mit zwei Literalen gesucht und diese werden belegt. Erst dann wird eine beliebige Klausel (bzw. ein beliebiges Literal) gewählt. Die Laufzeit ist beschränkt durch $\mathcal{O}(7^{\frac{n}{3}})$.
	\end{theorem}
	Das Erfüllbarkeitsproblem, in dem jede Klausel aus maximal zwei Variablen besteht, wird 2-SAT genannt. Dieses Problem kann in polynomieller Zeit gelöst werden.
	\begin{theorem}
		Im folgenden wird ein probabilistischer Algorithmus für 2-SAT eingeführt.
		\begin{enumerate}
			\item $\alpha := (0,0,...,0)$
			\item for $i = 0$ to $f(F)$
			\item if $\alpha(F) = 1$: return True
			\item wähle eine zufällige Klausel $C$ mit $\alpha(C) = 0$
			\item wähle ein zufälliges Literal $x$ aus $C$
			\item setze $\alpha(x) = \overline{\alpha(x)}$
		\end{enumerate}
		Die Funktion $f: F \mapsto n \in \mathbb{N}$ wird später definiert.\\
		Ist $F$ unerfüllbar, so funktioniert der Algorithmus korrekt. Ist $F$ erfüllbar, so findet der Algorithmus eine erfüllende Belegung mit Wahrscheinlichkeit $p \geq \frac{1}{2}$.\\
		Ist $\alpha^*$ eine erfüllende Belegung und $\alpha$ eine beliebige andere Belegung, mit Hamming-Abstand $i$ zu $\alpha^*$, so definieren wir uns $T(i)$ als die erwartete Anzahl an Bit-Flips, die nötig sind, um $\alpha$ in eine erfüllende Belegung zu transformieren. Man kann sehen, dass $T(n) = n^2$. Die erwartete Anzahl an Bitflips ist also $\mathcal{O}(n^2)$. Wählt man nun $f(F) = 2n^2$, so ist die Erfolgswahrscheinlichkeit von $\frac{1}{2}$ garantiert.
	\end{theorem}
	\section{Probabilistische Algorithmen}
	\subsection{Min-Cut}
	Dieses Problem ist in P. Eine effiziente Lösung ist durch den Ford-Fulkerson Algorithmus mithilfe dem Max-Flow/Min-Cut Lemmas möglich. Im Folgenden wird ein effizienter probabilistischer Algorithmus besprochen.
	\begin{enumerate}
		\item WHILE $\left|V\right| > 2$ DO
		\item wähle $(u,v) \in_R E$
		\item kontrahiere $(u,v)$
		\item ENDWHILE
	\end{enumerate}
	\begin{theorem}
		Der Algorithmus hat Laufzeit $\mathcal{O}(n^2 (\log n)^2)$. Der Algorithmus findet immer einen Schnitt. Der Algorithmus benötigt für jede Instanz $n-1$ Schritte. Für einen gegebenen minimalen Schnitt $C$ ist die Wahrscheinlichkeit, dass der Algorithmus $C$ findet ist $\geq \frac{2}{n(n-1)}$. Es genügen also $\mathcal{O}(n^2)$ Wiederholungen für eine konstant kleine Fehlerwahrscheinlichkeit.
	\end{theorem}
	In jedem Schritt des Algorithmus wird gehofft, dass keine Kante $e$ aus dem minimal cut $C$ gezogen wird. Im letzten Schritt beträgt die Fehlerwahrscheinlichkeit dafür aber $\frac{2}{3}$. Um dem entgegen zu wirken, ist die Idee, den Algorithmus ein wenig umzubauen. Nach etwa $n\left(\frac{\sqrt{2} - 1}{\sqrt{2}}\right)$ Schritten wird der bisher erzeugte Teilgraph $H$ von $G$ bestimmt. Für diesen Graphen wird der Algorithmus zwei separate Male ausgeführt und der kleinere der beiden Cuts wird gewählt. Eine Kontraktion ist in $\mathcal{O}(n)$ mithilfe der Adjazenzmatrix möglich, also wird die Laufzeit \[T(n) = \underbrace{\left(1-\frac{1}{\sqrt{2}}\right)n}_{\text{Anzahl Runden}} \cdot \underbrace{cn}_{\text{Laufzeit Kontraktion}} + \underbrace{2T\left(\frac{n}{\sqrt{2}}\right)}_{\text{Laufzeit Rekursion}}\]
	Mittels Master-Theorem lässt sich die Laufzeit bestimmen als $T(n) = \mathcal{O}(n^2 \log n)$.\\
	Die Wahrscheinlichkeit, dass $C$ nun die ersten $n\left(1-\frac{1}{\sqrt{2}}\right)$ Schritte überlebt, ist nun $\approx \frac{1}{2}$. Mittels induktivem Einsetzen kann überprüft werden, dass die Erfolgswahrscheinlichkeit $p(n) \geq \frac{1}{\log n}$ ist. Es genügen daher $\log n$ Wiederholungen für eine konstante Fehlerwahrscheinlichkeit. Die gesamte Laufzeit ist daher $\mathcal{O}(n^2 (\log n)^2)$.
	\subsection{All pairs shortest paths (APSP)}
	Wird jeder Pfad explizit ausgegeben, so kann die Ausgabe sehr groß sein. Man kann leicht ein Beispiel konstruieren, wo die gesamte Länge aller kürzesten Pfade $\Omega(n^3)$ ist. In diesem Fall wäre ein effizienter Algorithmus rein akademisch, da die Ausgabe ohnehin hohe Laufzeit benötigt.\\
	\begin{definition}
		Das Problem wird gelöst mithilfe der \underline{Shortest Path Matrix} $S \in \mathbb{R}^{n\times n}$. Diese ist definiert als $S_{i,j} = k \in V$, wenn $k$ Nachbar von $i$ in einem kürzesten $i-j$ Pfad ist. Bemerke, dass $S$ nicht eindeutig ist, da es mehrere kürzeste Wege geben kann. Mittels Dijkstra kann diese Matrix in $\mathcal{O}(n^3)$ berechnet werden. 
	\end{definition}
	Der folgende Algorithmus berechnet $S$ indem Matrizenmultiplikation verwendet wird. Sei $MM(n)$ die beste bekannte Laufzeit für Matrixmultiplikation, dann ist die Laufzeit von dem Algorithmus $\mathcal{O}(MM(n)\log^2 n)$. 
	\begin{definition}
		Wir definieren die Distanzmatrix $D$ mittels $d_{i,j}$ = Länge eines kürzesten $i-j$-Pfades. Wir schreiben $\delta(G)$ für den Durchmesser eines Graphen.
	\end{definition}
	\begin{lemma}
		Für die Adjazenzmatrix eines Graphen $G$, $u,v \in V$ und $k \in \mathbb{N}$ ist $A^k$ die Matrix aller $k$-Pfade. In anderen Worten $a^k_{u,v}$ ist die Anzahl der $u-v$-Pfade der Länge $k$.
	\end{lemma}
	Für $Z=A^2$ kann man einen Graphen $G'$ mit Kanten $E'$ definieren, sodass \[E' = E \cup \{(i,j) \mid d_{i,j} = 2\}\] Die Adjazenzmatrix ist dann $A'$ gegeben durch \[a'_{i,j} = \begin{cases}
		0, & i=j \lor (z_{i,j} = 0 \land a_{i,j} = 0)\\
		1, & \text{ sonst}
	\end{cases}\]
	Es folgt, dass $A'$ in $MM(n)$ berechnet werden kann.\\
	Es ist nun klar, dass falls $\delta(G) \leq 2$, dann ist $D=2A'-A$.
	\begin{lemma}
		Für alle $i,j \in V$ gilt $d_{i,j}$ gerade $\Rightarrow$ $d_{i,j} = 2d'_{i,j}$ und $d_{i,j}$ ungerade $\Rightarrow$ $d_{i,j} = 2d'_{i,j}-1$.
	\end{lemma}
	\begin{lemma}
		Für alle $i,j \in V$ und $\forall k \in N(i)$ ist $d_{i,j} - 1 \leq d_{k,j} \leq d_{i,j}+1$ und $\exists k \in N(i)$ sodass $d_{i,j}-1 = d_{k,j}$.
	\end{lemma}
	\begin{lemma}
		$\forall i,j \in V$ gilt $\forall k \in N(i)$, dass $d_{i,j}$ gerade $\Rightarrow$ $d'_{k,j} \geq d'_{i,j}$ und \\
		$d_{i,j}$ ungerade $\Rightarrow$ $d'_{k,j} \leq d'_{i,j}$ und $\exists k \in N(i)$ sodass $d'_{k,j} < d'_{i,j}$.\\
		Insbesondere folgt $d_{i,j}$ gerade $\Rightarrow \sum_{k \in N(i)} d'_{k,j} \geq d(i)\cdot d'_{i,j}$ und\\
		$d_{i,j}$ ungerade $\Rightarrow \sum_{k \in N(i)} d'_{k,j} < d(i)\cdot d'_{i,j}$.\\
		Weiter kann man sehen, dass $\sum_{k \in N(i)} d'_{k,j} = (A\cdot D')_{i,j}$.
	\end{lemma}
	Der Algorithmus zur Berechnung der $D$ Matrix (genannt $APD$, \underline{all pairs distance}) ist nun\\
	\underline{Funktion APD($A$ Adjazenzmatrix von $G$):}
	\begin{enumerate}
		\item $Z = A^2$
		\item Berechne $A'$
		\item if $\forall i,j \in V, \; i\neq j$ gilt $a'_{i,j} = 1$ then return $D = 2A'-A$
		\item $D' = APD(A')$
		\item $F = A\cdot D'$
		\item for each $(i,j) \in V\times V$:
		\item if $f_{i,j} \geq d'_{i,j}-1$ then $d_{i,j} = 2d'_{i,j}$
		\item else $d_{i,j} = 2d'_{i,j}-1$
		\item return $D$
	\end{enumerate}
	Bezeichne $T(n,k)$ die Laufzeit des Algorithmus für einen Graphen auf $n$ Knoten mit Durchmesser $k$. Wir wissen, dass $T(n,2) = MM(n)$. Außerdem ist \[T(n,k) = MM(n) + \mathcal{O}(n^2) + T\left(n,\left\lceil\frac{k}{2}\right\rceil\right) + MM(n) = \mathcal{O}(MM(n)\cdot \log(n)\]
	\subsection{Boolean Product Witness}
	Seien $A,B \in \{0,1\}^{n\times m}$.
	\begin{definition}
		Wir definieren $A\odot B = C$ durch \[c_{i,j} = \lor_{k=1}^n a_{i,k} \land b_{k,j}\]
		Die BPW Matrix ist definiert durch \[w_{i,j} = \begin{cases}
			0, & c_{i,j} = 0\\
			k, & c_{i,j} = 1 \text{ und } a_{i,k} \land b_{k,j} = 1
		\end{cases}\]
	Im zweiten Fall heißt $w_{i,j} = k$ ein Zeuge.
	Außerdem definiert man die Matrix $\hat{A}$ durch $\hat{a}_{i,k} = k a_{i,k}$. Diese kann in $\mathcal{O}(n^2)$ berechnet werden.
	\end{definition}
	Gibt es für $(i,j)$ genau einen Zeugen, so gilt \[(\hat{A}\cdot B)_{i,j} = k\]
	Sei nun $w>0$ die Anzahl der Zeugen für eine Position $(i,j)$. Sei außerdem $r = 2^s$ für ein $s \in \mathbb{N}$, sodass $$\frac{n}{2} \leq r\cdot w \leq n$$
	Unter Gleichverteilung werden nun zufällig $r$ Elemente aus $\{1,...,n\}$ gezogen und daraus die Menge $R$ erstellt. Es gilt dann \[\mathbb{P}[\text{in $R$ gibt es genau einen Zeugen für $(i,j)$}] = p = \frac{w\binom{n-w}{r-1}}{\binom{n}{r}}\]
	\begin{lemma}
		$p \geq \frac{1}{2^e}$
	\end{lemma}
	\begin{definition}
		Wir definieren $B^R$ als die Matrix, die aus $B$ gewonnen wird, wenn alle Zeilen $z$ mit $z \notin R$ auf 0 gesetzt werden.
	\end{definition}
	Falls es in $R$ genau einen Zeugen $l$ für $A,B$ gibt, so gilt $(\hat{A}B^R)_{i,j} = l$. 
	Auf dieser Basis kann nun ein Algorithmus zur Lösung des BPW Problems konstruiert werden.
	\begin{enumerate}
		\item $W = -A\cdot B$
		\item for $t=0$ to $\lfloor\log n\rfloor$
		\item $r = 2^t$
		\item for $l = 1$ to $\lceil2e \log n\rceil$
		\item wähle $R \in_R \{1,...,n\}$ mit $\left|R\right| = r$
		\item Berechne $\hat{A}$, $B^R$ und $Z = \hat{A} B^R$.
		\item for $(i,j)$
		\item if $w_{i,j}<0$ and $z_{i,j}$ ist Zeuge then $w_{i,j} = z_{i,j}$
		\item endfor
		\item endfor
		\item endfor
		\item for $(i,j)$ finde Zeuge $w_{i,j}$
	\end{enumerate}
	Die Laufzeit des Algorithmus ist beschränkt auf $\mathcal{O}(MM(n) \cdot \log^2 n)$.
	Mit dieser Überlegung kann nun das APSP Problem gelöst werden. Dafür ist anzumerken, dass für $j \in N_G(i)$ gilt, dass die Distanz zu $k$ $d_{i,k} = d_{j,k} + s$ für $s \in \{-1,0,1\}$ erfüllt.\\
	\begin{enumerate}
		\item $D = APD(A)$
		\item for $s \in \{0,1,2\}$
		\item Berechne $D^{(s)}$ via $d_{i,j}^{(s)} = 1 \Leftrightarrow d_{i,j} = s-1 \mod 3$
		\item $W^{(s)} = BPW(A,D^{(s)})$
		\item endfor
		\item Berechne $S$ via $s_{i,j} = w_{i,j}^{d_{i,j} \mod 3}$
	\end{enumerate}
	Die Gesamtkomplexität des Algorithmus ist $\mathcal{O}(MM(n) \log^2 n)$.
	\subsection{Perfektes Matching auf bipartiten Graphen}
	Das Problem ist effizient deterministisch zu lösen, aber Algorithmen sind üblicherweise sehr kompliziert. Wir stellen daher stattdessen einen einfachen probabilistischen Algorithmus vor.
	\begin{definition}
		Sie $G = (V_1 \cup V_2, E)$ ein biparttier Graph mit $\left|V_1\right| = \left|V_2\right| = n$. Man definiert die $n\times n$ Bipartitionsmatrx $A_G$ durch \[A_G = \begin{cases}
			x_{i,j}, & (i,j) \in E\\
			0, & \text{ sonst}
		\end{cases}\]
	Die Determinante $D$ der Matrix wird wie üblich bestimmt als \[\det(A) = \sum_{\pi \in S_n} sgn(\pi) \prod_{i=1}^{n} a_{i,\pi(i)}\]
	Es ist offensichtlich, dass $\det(A_G)$ ein Polynom in den $x_{i,j}$ ist.
	\end{definition}
	\begin{theorem}
		Es gibt ein perfektes Matching in $G$ $\Leftrightarrow$ $\det(A_G) \not \equiv 0$.
	\end{theorem}
	Zu bestimmen, ob die Determinante der Matrix das Null-Polynom ist, kann im Allgemeinen sehr aufwändig sein. Ein probabilistischer Ansatz ist es, zufällige Werte in das Polynom einzusetzen und zu überprüfen, ob die Funktion 0 ausgibt. Dabei hilft das folgende Lemma.
	\begin{lemma}
		Sei $g$ ein Polynom mit $m$ Variablen und Grad $\leq d$. Dann hat $p$ $\leq mdM^{m-1}$, wenn die Parameter $a_1,...,a_m \in \{0,1,...,M-1\}$.
	\end{lemma}
	Für das Polynom der Determinanten gilt $m\leq n^2, d=1$. Der Algorithmus zum Überprüfen, ob das Polynom dem Nullpolynom entspricht, besteht nun daraus, zufällige Werte für die $x_{i,j}$ zu wählen und die Determinante der daraus entstandenen Matrix zu berechnen.
	\begin{enumerate}
		\item Berechne $A_G$
		\item belege $x_{i,j} \in_R \{0,...,M-1\}$ für alle $i,j$
		\item setze diese Werte in $A_G$ ein und bezeichne das Resultat als $A_G'$
		\item if $\det(A_G') \neq 0$: es gibt perfektes Matching
		\item else: es gibt (wahrscheinlich) kein perfektes Matching
	\end{enumerate}
	Der Algorithmus hat eine Fehlerwahrscheinlichkeit $\leq \frac{n^2}{M}$. Wählt man $M = 2n^2$, so ist die Fehlerwahrscheinlichkeit $\leq \frac{1}{2}$.
	\subsection{Perfektes Matching auf allgemeinen Graphen}
	Aus offensichtlichen Gründen gehen wir davon aus, dass $n$ gerade ist.
	\begin{definition}
		Wir definieren wieder eine leicht veränderte Adjazenzmatrix
		\[(A_G)_{i,j} = \begin{cases}
			0, & (i,j) \notin E\\
			x_{i,j}, & (i,j) \in E \land i<j\\
			-x_{i,j}, & (i,j) \in E \land j<i
		\end{cases}\]
	\end{definition}
	Ein Matching ist dann eine Permutation $\pi$ mit $\pi^2 = id$ und $\pi(i) \neq i$. Die Idee ist nun, wieder über die Determinante der Matrix zu argumentieren. Es gilt \[\det(A_G) = \sum_{\pi \in S_n} sgn(\pi) \prod_{i=1}^{n} a_{i,\pi(i)}\] Es gilt wieder das selbe Resultat wie für bipartite Graphen. \begin{lemma}
		$G$ hat ein perfektes Matching $\Leftrightarrow \det(A_G) \not\equiv 0$.
	\end{lemma}
	Es ist klar, dass der Algorithmus für bipartite Graphen dann auch für allgemeine Graphen funktioniert.
	\subsection{Perfektes Matching finden}
	Mit den vorherigen Teilen kann nun bestimmt werden, ob in einem Graphen ein Matching existiert. Ein solches zu finden, benötigt aber zunächst einige Überlegungen.
	\begin{definition}
		Sei $S = \{x_1,...,x_n\}$ eine endliche Menge. $F = \{S_1,...,S_k\}$ sodass $S_j \subseteq S$ heißt Mengensystem. Es ist klar, dass $\left|F\right| \leq 2^n$\\
		Sei $w:S \to \{1,2,...,2n\}$ eine Funktion die jedem Element aus $S$ ein Gewicht zuordnet. $w(S_j)$ sei eine verkürzte Schreibweise für $\sum_{x \in S_j} w(x)$.
	\end{definition}
	\begin{lemma}[Isolierungslemma]
		Ist $w$ zufällig und unter Gleichverteilung gewählt, so ist \[\mathbb{P}[\exists ! S_i \in F : w(S_i) \text{ minimal }] \geq \frac{1}{2}\]
	\end{lemma}
	Die Idee ist nun, mit diesem Lemma einen Algorithmus zur Bestimmung eines perfekten Matchings in bipartiten Graphen zu konstruieren. Auf Existenz eines perfekten Matchings können wir bereits überprüfen.\\
	Sei nun $G = (U\cup V,E)$ ein bipartiter Graph mit perfektem Matching und $\left|U\right| = \left|V\right|$. Wir statten die Kanten mit Gewichten $w$ in $\{1,2,...,2m\}$ aus. Im Rahmen des Lemmas sein $S = E$ und $F$ die Menge der perfekten Matchings. Wir definieren $A \in \mathbb{R}^{n\times n}$ mit \[a_{i,j} = \begin{cases}
		1, & (u_i,v_j) \in E\\
		0, & \text{ sonst}
	\end{cases}\]
	Daraus definieren wir eine zweite Matrix $B$ mit \[b_{i,j} = \begin{cases}
		2^{w_{i,j}}, & (u_i,v_j) \in E\\
		0, & \text{ sonst}
	\end{cases}\]
	\begin{lemma}
		Falls $G$ genau ein perfektes Matching mit minimalem Gewicht $w$ hat, so ist $\det(B) \neq 0$ und $2^w$ ist die größte Zweierpotenz die $\det(B)$ teilt.
	\end{lemma}
	\begin{lemma}
		Gibt es in $G$ genau ein perfektes Matching $M$ minimalen Gewichts $w$, dann gilt \[(u_i,v_j) \in M \Leftrightarrow \frac{\det(B_{i,j})}{2^w} \mod 2 = 0\] Dabei ist $B_{i,j}$ die Matrix $B$ mit 0 an der Stelle $(i,j)$.
	\end{lemma}
	Der Algorithmus ist nun klar. Man überprüft einfach für jede Kante, ob das obige Lemma erfüllt ist. Wenn ja, wird sie in das Matching aufgenommen.
	\subsection{Rot-Blau-perfektes Matching}
	Das folgende Problem kann mit einem probabilistischen Algorithmus effizient gelöst werden. Ein polynomieller deterministischer Algorithmus ist hingegen nicht bekannt.\\
	Gegeben sei ein bipartiter Graph $G=(U\cup V, E)$ mit $\left|U\right| = \left|V\right| = n$ und mit einer Färbung $c$ der Kanten $c:E \to \{r,b\}$, jede Kante ist also rot oder blau. Außerdem gibt es ein $k\leq n$. Die Frage ist nun, gibt es ein perfektes Matching mit genau $k$ roten Kanten?\\
	Die Idee ist wieder, das Isolationslemma zu verwenden. Dafür wählen wir $S=E$ und $F$ als die Menge der perfekten Matchings mit genau $k$ roten Kanten. Weiter definieren wir uns $f:E \to \{p,2p\}$ durch \[f(e) = \begin{cases}
		2p, & c(e) = r\\
		p, & c(e) = b
	\end{cases}\] wobei $p=3n^3$.
	Daraus wird nun wieder eine Matrix gebaut, $B \in \mathbb{R}^{n\times n}$ mit \[b_{i,j} = \begin{cases}
		2^{w_{i,j} + f((i,j))}, & (i,j) \in E\\
		0, & \text{ sonst}
	\end{cases}\]
	Für ein perfektes Matching $\sigma$ mit genau $k$ roten Kanten gilt nun $$\prod_{i=1}^n b_{i,\sigma(i)} = 2^{w(\sigma) + (n+k)p} \leq 2^{n\cdot 2m + (n+k)p} \leq 2^{2n^3 + (n+k)p} \leq 2^{(n+k+1)p}$$ Es folgt, dass die Terme in $\det(B)$, die ein perfektes Matching mit mehr als $k$ roten Kanten implizieren, diesen Term nicht annullieren können. Es gibt außerdem höchstens $n!$ viele perfekte Matchings mit weniger als $k$ roten Kanten. Die Summe solcher Terme ist kleiner als $2^{n^2+(n+k-1)p+2n^3}$ was wiederum kleiner als $2^{w(\sigma)+(n+k)p}$ ist. Diese Summe kann den Term also auch nicht annullieren.\\
	Der Algorithmus wählt die Gewichtsfunktion $w$ zufällig und berechnet $\det(B)$. Das ist eine Summe von Zweierpotenzen. Der Algorithmus gibt aus, dass es ein perfektes Matching mit $k$ roten Kanten gibt, genau dann, wenn in dieser Summe eine Zweierpotenz $2^r$ vorkommt, sodass $2^{(k+1)p} <2^r <2^{(k+n)p}$.
\end{document}