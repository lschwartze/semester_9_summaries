\documentclass[a4paper, 12pt]{article}

\usepackage{fullpage}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb}
\usepackage[explicit]{titlesec}
\usepackage{ulem}
\usepackage[onehalfspacing]{setspace}
\usepackage{amsthm}

\theoremstyle{plain}
\newtheorem{theorem}{Satz}[section] % reset theorem numbering for each chapter

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition} % definition numbers are dependent on theorem numbers
\theoremstyle{lemma}
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Bemerkung}

\theoremstyle{corollary}
\newtheorem{corollary}[theorem]{Korollar}

\theoremstyle{example}
\newtheorem{example}[theorem]{Beispiel}

\titleformat{\subsection}
{\small}{\thesubsection}{1em}{\uline{#1}}
\begin{document}
	\begin{titlepage} 
		\title{Algorithmen für schwierige Probleme}
		\clearpage\maketitle
		\thispagestyle{empty}
	\end{titlepage}
	\tableofcontents
	\newpage
	\section{3-SAT und Vertex Cover}
	\subsection{Vertex Cover}
	\begin{definition}
		Ein Vertex Cover für einen Graphen $G$ ist eine Teilmenge $C \subseteq V$ der Knoten, sodass $\forall e = (u,v) \in E$ gilt $u \in C$ oder $v \in C$. 
	\end{definition}
	\begin{definition}
		Für zwei Probleme $A$, $B$ schreiben wir $A \preceq B$, wenn man $A$ effizient auf $B$ transformieren kann.
	\end{definition}
	\begin{theorem}
		Der Greedy Algorithmus, der immer den Knoten höchsten Grades wählt, kann beliebig schlechte Ergebnisse liefern.
	\end{theorem}
	\begin{theorem}
		Der folgende Algorithmus liefert eine 2-Faktor-Approximation an das optimale Vertex Cover.
		\begin{enumerate}
			\item setze $C= \varnothing$
			\item WHILE $E \neq \varnothing$
			\item wähle eine Kante $(u,v)$
			\item setze $V = V\setminus \{u,v\}$, $E = {e = (w,x) \in E \; | \; w,x \notin \{u,v\}}$ und $C = C \cup \{u,v\}$.
		\end{enumerate}
	\end{theorem}
	\begin{theorem}
		Der folgenden Ansatz benutzt außerdem einen Parameter $k$ als Eingabe und entscheidet, ob es ein Vertex Cover der Größe $\leq k$ gibt.
		\begin{enumerate}
			\item FUNCTION VCover($G,C,l$)
			\item if $E = \varnothing$ return True
			\item if $l = k$ return False
			\item Wähle eine Kante $(u,v)$ in $G$
			\item if VCover($G\setminus \{u\}, C \cup \{u\}, l+1$)
			\item return True
			\item else return VCover($G\setminus \{v\}, C\cup \{v\}, l+1$)
		\end{enumerate}
	Die Laufzeit ist offensichtlich $2^k \mathcal{O}(n)$.
	\end{theorem}
	\subsection{SAT}
	Eine Formel $F$ ist in KNF gegeben, also als Konjunktion von Disjunktionen von Literalen. Eine Belegung ist eine Funktion, die jeder Variable einen Wert zuweist. Eine partielle Belegung weist nur einer Teilmenge aller Variablen Werte zu und lässt die restlichen undefiniert.
	\begin{lemma}
		Reduktion von 3-Färbbarkeit auf SAT.\\
		Für einen Graphen $G$ wollen wir eine Formel $F$ konstruieren. Zunächst definieren wir die Menge der Variablen von $F$ als \[VAR = \{x_v^1, x_v^2, x_v^3: \; v \in V\}\] für drei verschiedene Farben. In einer Lösung muss jeder Knoten eine Farbe bekommen, d.h wir brauchen die $\left|V\right|$ Klauseln \[(x_v^1 \lor x_v^2 \lor x_v^3)\] Außerdem dürfen zwei benachbarte Knoten nicht dieselbe Farbe bekommen, das heißt, es ergeben sich die $3\left|E\right|$ Klauseln \[(\lnot {x_v^1} \lor \lnot {x_w^1}) \land (\lnot {x_v^2} \lor \lnot {x_w^2}) \land (\lnot {x_v^3} \lor \lnot {x_w^3})\] 
	\end{lemma}
	\begin{theorem}
		Der folgende \underline{Backtracking} Algorithmus bietet einen guten Ansatz, um eine Formel $F$ auf Erfüllbarkeit zu überprüfen.
		\begin{enumerate}
			\item FUNCTION search($F, \alpha$ partielle Belegung)
			\item if $\alpha$ belegt alle Variablen: return $\alpha(F)$
			\item if $\alpha$ belegt eine Klausel mit 0: return False
			\item if search($F, \alpha0$) = True: return True
			\item else: return search($F,\alpha1$)
		\end{enumerate}
		Dieser Algorithmus kann sogar noch weiter verbessert werden, indem zuerst nach Klauseln mit nur einem Literal gesucht wird und dann diese belegt werden. Wenn diese nicht existieren, wird nach Klauseln mit zwei Literalen gesucht und diese werden belegt. Erst dann wird eine beliebige Klausel (bzw. ein beliebiges Literal) gewählt. Die Laufzeit ist beschränkt durch $\mathcal{O}(7^{\frac{n}{3}})$.
	\end{theorem}
	Das Erfüllbarkeitsproblem, in dem jede Klausel aus maximal zwei Variablen besteht, wird 2-SAT genannt. Dieses Problem kann in polynomieller Zeit gelöst werden.
	\begin{theorem}
		Im folgenden wird ein probabilistischer Algorithmus für 2-SAT eingeführt.
		\begin{enumerate}
			\item $\alpha := (0,0,...,0)$
			\item for $i = 0$ to $f(F)$
			\item if $\alpha(F) = 1$: return True
			\item wähle eine zufällige Klausel $C$ mit $\alpha(C) = 0$
			\item wähle ein zufälliges Literal $x$ aus $C$
			\item setze $\alpha(x) = \overline{\alpha(x)}$
		\end{enumerate}
		Die Funktion $f: F \mapsto n \in \mathbb{N}$ wird später definiert.\\
		Ist $F$ unerfüllbar, so funktioniert der Algorithmus korrekt. Ist $F$ erfüllbar, so findet der Algorithmus eine erfüllende Belegung mit Wahrscheinlichkeit $p \geq \frac{1}{2}$.\\
		Ist $\alpha^*$ eine erfüllende Belegung und $\alpha$ eine beliebige andere Belegung, mit Hamming-Abstand $i$ zu $\alpha^*$, so definieren wir uns $T(i)$ als die erwartete Anzahl an Bit-Flips, die nötig sind, um $\alpha$ in eine erfüllende Belegung zu transformieren. Man kann sehen, dass $T(n) = n^2$. Die erwartete Anzahl an Bitflips ist also $\mathcal{O}(n^2)$. Wählt man nun $f(F) = 2n^2$, so ist die Erfolgswahrscheinlichkeit von $\frac{1}{2}$ garantiert.
	\end{theorem}
	\subsection{Min-Cut}
	Dieses Problem ist in P. Eine effiziente Lösung ist durch den Ford-Fulkerson Algorithmus mithilfe dem Max-Flow/Min-Cut Lemmas möglich. Im Folgenden wird ein effizienter probabilistischer Algorithmus besprochen.
	\begin{enumerate}
		\item WHILE $\left|V\right| > 2$ DO
		\item wähle $(u,v) \in_R E$
		\item kontrahiere $(u,v)$
		\item ENDWHILE
	\end{enumerate}
	\begin{theorem}
		Der Algorithmus hat Laufzeit $\mathcal{O}(n^2 (\log n)^2)$. Der Algorithmus findet immer einen Schnitt. Der Algorithmus benötigt für jede Instanz $n-1$ Schritte. Für einen gegebenen minimalen Schnitt $C$ ist die Wahrscheinlichkeit, dass der Algorithmus $C$ findet ist $\geq \frac{2}{n(n-1)}$. Es genügen also $\mathcal{O}(n^2)$ Wiederholungen für eine konstant kleine Fehlerwahrscheinlichkeit.
	\end{theorem}
	In jedem Schritt des Algorithmus wird gehofft, dass keine Kante $e$ aus dem minimal cut $C$ gezogen wird. Im letzten Schritt beträgt die Fehlerwahrscheinlichkeit dafür aber $\frac{2}{3}$. Um dem entgegen zu wirken, ist die Idee, den Algorithmus ein wenig umzubauen. Nach etwa $n\left(\frac{\sqrt{2} - 1}{\sqrt{2}}\right)$ Schritten wird der bisher erzeugte Teilgraph $H$ von $G$ bestimmt. Für diesen Graphen wird der Algorithmus zwei separate Male ausgeführt und der kleinere der beiden Cuts wird gewählt. Eine Kontraktion ist in $\mathcal{O}(n)$ mithilfe der Adjazenzmatrix möglich, also wird die Laufzeit \[T(n) = \underbrace{\left(1-\frac{1}{\sqrt{2}}\right)n}_{\text{Anzahl Runden}} \cdot \underbrace{cn}_{\text{Laufzeit Kontraktion}} + \underbrace{2T\left(\frac{n}{\sqrt{2}}\right)}_{\text{Laufzeit Rekursion}}\]
	Mittels Master-Theorem lässt sich die Laufzeit bestimmen als $T(n) = \mathcal{O}(n^2 \log n)$.\\
	Die Wahrscheinlichkeit, dass $C$ nun die ersten $n\left(1-\frac{1}{\sqrt{2}}\right)$ Schritte überlebt, ist nun $\approx \frac{1}{2}$. Mittels induktivem Einsetzen kann überprüft werden, dass die Erfolgswahrscheinlichkeit $p(n) \geq \frac{1}{\log n}$ ist. Es genügen daher $\log n$ Wiederholungen für eine konstante Fehlerwahrscheinlichkeit. Die gesamte Laufzeit ist daher $\mathcal{O}(n^2 (\log n)^2)$.
	\subsection{All pairs shortest paths (APSP)}
	Wird jeder Pfad explizit ausgegeben, so kann die Ausgabe sehr groß sein. Man kann leicht ein Beispiel konstruieren, wo die gesamte Länge aller kürzesten Pfade $\Omega(n^3)$ ist. In diesem Fall wäre ein effizienter Algorithmus rein akademisch, da die Ausgabe ohnehin hohe Laufzeit benötigt.\\
	\begin{definition}
		Das Problem wird gelöst mithilfe der \underline{Shortest Path Matrix} $S \in \mathbb{R}^{n\times n}$. Diese ist definiert als $S_{i,j} = k \in V$, wenn $k$ Nachbar von $i$ in einem kürzesten $i-j$ Pfad ist. Bemerke, dass $S$ nicht eindeutig ist, da es mehrere kürzeste Wege geben kann. Mittels Dijkstra kann diese Matrix in $\mathcal{O}(n^3)$ berechnet werden. 
	\end{definition}
	Der folgende Algorithmus berechnet $S$ indem Matrizenmultiplikation verwendet wird. Sei $MM(n)$ die beste bekannte Laufzeit für Matrixmultiplikation, dann ist die Laufzeit von dem Algorithmus $\mathcal{O}(MM(n)\log^2 n)$. 
	\begin{definition}
		Wir definieren die Distanzmatrix $D$ mittels $d_{i,j}$ = Länge eines kürzesten $i-j$-Pfades. Wir schreiben $\delta(G)$ für den Durchmesser eines Graphen.
	\end{definition}
	\begin{lemma}
		Für die Adjazenzmatrix eines Graphen $G$, $u,v \in V$ und $k \in \mathbb{N}$ ist $A^k$ die Matrix aller $k$-Pfade. In anderen Worten $a^k_{u,v}$ ist die Anzahl der $u-v$-Pfade der Länge $k$.
	\end{lemma}
	Für $Z=A^2$ kann man einen Graphen $G'$ mit Kanten $E'$ definieren, sodass \[E' = E \cup \{(i,j) \mid d_{i,j} = 2\}\] Die Adjazenzmatrix ist dann $A'$ gegeben durch \[a'_{i,j} = \begin{cases}
		0, & i=j \lor (z_{i,j} = 0 \land a_{i,j} = 0)\\
		1, & \text{ sonst}
	\end{cases}\]
	Es folgt, dass $A'$ in $MM(n)$ berechnet werden kann.\\
	Es ist nun klar, dass falls $\delta(G) \leq 2$, dann ist $D=2A'-A$.
	\begin{lemma}
		Für alle $i,j \in V$ gilt $d_{i,j}$ gerade $\Rightarrow$ $d_{i,j} = 2d'_{i,j}$ und $d_{i,j}$ ungerade $\Rightarrow$ $d_{i,j} = 2d'_{i,j}-1$.
	\end{lemma}
	\begin{lemma}
		Für alle $i,j \in V$ und $\forall k \in N(i)$ ist $d_{i,j} - 1 \leq d_{k,j} \leq d_{i,j}+1$ und $\exists k \in N(i)$ sodass $d_{i,j}-1 = d_{k,j}$.
	\end{lemma}
	\begin{lemma}
		$\forall i,j \in V$ gilt $\forall k \in N(i)$, dass $d_{i,j}$ gerade $\Rightarrow$ $d'_{k,j} \geq d'_{i,j}$ und \\
		$d_{i,j}$ ungerade $\Rightarrow$ $d'_{k,j} \leq d'_{i,j}$ und $\exists k \in N(i)$ sodass $d'_{k,j} < d'_{i,j}$.\\
		Insbesondere folgt $d_{i,j}$ gerade $\Rightarrow \sum_{k \in N(i)} d'_{k,j} \geq d(i)\cdot d'_{i,j}$ und\\
		$d_{i,j}$ ungerade $\Rightarrow \sum_{k \in N(i)} d'_{k,j} < d(i)\cdot d'_{i,j}$.\\
		Weiter kann man sehen, dass $\sum_{k \in N(i)} d'_{k,j} = (A\cdot D')_{i,j}$.
	\end{lemma}
	Der Algorithmus zur Berechnung der $D$ Matrix (genannt $APD$, \underline{all pairs distance}) ist nun\\
	\underline{Funktion APD($A$ Adjazenzmatrix von $G$):}
	\begin{enumerate}
		\item $Z = A^2$
		\item Berechne $A'$
		\item if $\forall i,j \in V, \; i\neq j$ gilt $a'_{i,j} = 1$ then return $D = 2A'-A$
		\item $D' = APD(A')$
		\item $F = A\cdot D'$
		\item for each $(i,j) \in V\times V$:
		\item if $f_{i,j} \geq d'_{i,j}-1$ then $d_{i,j} = 2d'_{i,j}$
		\item else $d_{i,j} = 2d'_{i,j}-1$
		\item return $D$
	\end{enumerate}
	Bezeichne $T(n,k)$ die Laufzeit des Algorithmus für einen Graphen auf $n$ Knoten mit Durchmesser $k$. Wir wissen, dass $T(n,2) = MM(n)$. Außerdem ist \[T(n,k) = MM(n) + \mathcal{O}(n^2) + T\left(n,\left\lceil\frac{k}{2}\right\rceil\right) + MM(n) = \mathcal{O}(MM(n)\cdot \log(n)\]
	\subsection{Boolean Product Witness}
	Seien $A,B \in \{0,1\}^{n\times m}$.
	\begin{definition}
		Wir definieren $A\odot B = C$ durch \[c_{i,j} = \lor_{k=1}^n a_{i,k} \land b_{k,j}\]
		Die BPW Matrix ist definiert durch \[w_{i,j} = \begin{cases}
			0, & c_{i,j} = 0\\
			k, & c_{i,j} = 1 \text{ und } a_{i,k} \land b_{k,j} = 1
		\end{cases}\]
	Im zweiten Fall heißt $w_{i,j} = k$ ein Zeuge.
	Außerdem definiert man die Matrix $\hat{A}$ durch $\hat{a}_{i,k} = k a_{i,k}$. Diese kann in $\mathcal{O}(n^2)$ berechnet werden.
	\end{definition}
	Gibt es für $(i,j)$ genau einen Zeugen, so gilt \[(\hat{A}\cdot B)_{i,j} = k\]
	Sei nun $w>0$ die Anzahl der Zeugen für eine Position $(i,j)$. Sei außerdem $r = 2^s$ für ein $s \in \mathbb{N}$, sodass $$\frac{n}{2} \leq r\cdot w \leq n$$
	Unter Gleichverteilung werden nun zufällig $r$ Elemente aus $\{1,...,n\}$ gezogen und daraus die Menge $R$ erstellt. Es gilt dann \[\mathbb{P}[\text{in $R$ gibt es genau einen Zeugen für $(i,j)$}] = p = \frac{w\binom{n-w}{r-1}}{\binom{n}{r}}\]
	\begin{lemma}
		$p \geq \frac{1}{2^e}$
	\end{lemma}
	\begin{definition}
		Wir definieren $B^R$ als die Matrix, die aus $B$ gewonnen wird, wenn alle Zeilen $z$ mit $z \notin R$ auf 0 gesetzt werden.
	\end{definition}
	Falls es in $R$ genau einen Zeugen $l$ für $A,B$ gibt, so gilt $(\hat{A}B^R)_{i,j} = l$. 
	Auf dieser Basis kann nun ein Algorithmus zur Lösung des BPW Problems konstruiert werden.
	\begin{enumerate}
		\item $W = -A\cdot B$
		\item for $t=0$ to $\lfloor\log n\rfloor$
		\item $r = 2^t$
		\item for $l = 1$ to $\lceil2e \log n\rceil$
		\item wähle $R \in_R \{1,...,n\}$ mit $\left|R\right| = r$
		\item Berechne $\hat{A}$, $B^R$ und $Z = \hat{A} B^R$.
		\item for $(i,j)$
		\item if $w_{i,j}<0$ and $z_{i,j}$ ist Zeuge then $w_{i,j} = z_{i,j}$
		\item endfor
		\item endfor
		\item endfor
		\item for $(i,j)$ finde Zeuge $w_{i,j}$
	\end{enumerate}
	Die Laufzeit des Algorithmus ist beschränkt auf $\mathcal{O}(MM(n) \cdot \log^2 n)$.
	Mit dieser Überlegung kann nun das APSP Problem gelöst werden. Dafür ist anzumerken, dass für $j \in N_G(i)$ gilt, dass die Distanz zu $k$ $d_{i,k} = d_{j,k} + s$ für $s \in \{-1,0,1\}$ erfüllt.\\
	\begin{enumerate}
		\item $D = APD(A)$
		\item for $s \in \{0,1,2\}$
		\item Berechne $D^{(s)}$ via $d_{i,j}^{(s)} = 1 \Leftrightarrow d_{i,j} = s-1 \mod 3$
		\item $W^{(s)} = BPW(A,D^{(s)})$
		\item endfor
		\item Berechne $S$ via $s_{i,j} = w_{i,j}^{d_{i,j} \mod 3}$
	\end{enumerate}
	Die Gesamtkomplexität des Algorithmus ist $\mathcal{O}(MM(n) \log^2 n)$.
\end{document}